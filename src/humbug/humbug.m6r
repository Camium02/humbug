Role:
    You are a world-class python programmer with a flair for building brilliant software

Context: humbug application
    humbug is a GUI-based application that allows a user to interact with one or more AI backends.

    Navigation is done using a keyboard and mouse.

    Context: Version
        This is version 0.1 of the application.

    Context: Screen display
        The primary screen display is a tabbed interface, where the tabs correspond to either conversations being
        had with one or more AI backends, or files being edited.

        Selecting a tab brings that conversation to the front of the tab group.

        Context: Tab types
            There are two distinct types of tabs:

            - Conversation tabs: For AI interactions
            - Editor tabs: For file editing

            Each type has its own distinct visual appearance and behavior.

            Context: Conversation tabs
                Each tab will be named with a conversation name.  This will default to "Conv <num>" where <num> is a
                simple incrementing number starting from 1 for each conversation created during the current run of the
                application (e.g., "Conv 1", "Conv 2", "Conv 3", etc.).  These numbers do not need to persist between
                different runs of the application.

                Each tab will have a close button (typically rendered as an "x" icon) that appears after the conversation
                name.  Clicking this close button will close the tab in the same way as clicking the "Close Conversation"
                menu item.

                The close button will be:

                - Always visible but not highlighted on the currently selected tab.
                - Hidden by default on non-selected tabs, appearing only when the tab is hovered over.
                - Use a transparent background when not hovered
                - Highlighted in red when the mouse hovers over the close button itself.

                Context: History display
                    Each message in the history appears as a distinct "card" that spans the full width of the history view.

                    Each card has:

                    - A header section with a dark bluish-grey (#2a3544) background containing the sender name
                        ("You", "Assistant", or "System Message")
                    - A content section with the message text that uses appropriate background colours:
                        - User messages: White text on #3c3c3c background
                        - AI responses: White text on #282828 background
                        - System messages: White text on #1a3a1a background (dark green)
                        - Error messages: White text on #3a1a1a background (dark red)
                    - A border in the same colour as the header (#2a3544)
                    - 8px spacing between cards
                    - 8px padding within the content area

                    The cards dynamically resize with the window:

                    - The width always matches the window width (minus margins and scroll bar)
                    - The height adjusts automatically based on the content
                    - Text wraps within the card boundaries
                    - Code blocks maintain their formatting while wrapping where possible

                    Context: Example layout
                        Here's an ASCII representation of the layout:

                        ```plaintext
                        +------------------------------------------+
                        |  You                                     |
                        |------------------------------------------|
                        |  This is a user message that wraps       |
                        |  across multiple lines as needed.        |
                        +------------------------------------------+
                                        ↕ 10px
                        +------------------------------------------+
                        |  Assistant                               |
                        |------------------------------------------|
                        |  This is an AI response that also wraps  |
                        |  across multiple lines as needed.        |
                        |                                          |
                        |  ```python                               |
                        |  def example():                          |
                        |      print("Code blocks maintain their   |
                        |            formatting")                  |
                        |  ```                                     |
                        +------------------------------------------+
                                        ↕ 10px
                        +------------------------------------------+
                        |  System Message                          |
                        |------------------------------------------|
                        |  This is a system message that wraps     |
                        |  across multiple lines as needed.        |
                        +------------------------------------------+
                        ```

            Context: Editor tabs
                Each editor tab will be named with the filename being edited.

                For new unsaved files this will be "Untitled-<num>" where <num> is a simple incrementing number
                starting from 1 for each new file created during the current run of the application.

                Like conversation tabs, editor tabs will have a close button that appears after the filename.

                If there are unsaved changes in the file, an asterisk (*) will appear after the filename.

                The close button behavior matches that of conversation tabs.

        Context: Syntax highlighting
            Code blocks and inline code will be syntax highlighted based on the programming language:

            - Keywords appear in pink (#ffc0eb)
            - Comments appear in green (#68d068)
            - Strings appear in red (#f06060)
            - Numbers appear in orange (#c08040)
            - Operators appear in light grey (#c0c0c0)
            - Functions and methods appear in light yellow (#e0e080)
            - Class and type names appear in light blue (#80b0f0)
            - Regular expressions appear in orange-brown (#c87050)
            - Element access appears in light blue (#90e0e8)
            - HTML/CSS-specific:
                - HTML tags appear in pink (#ffc0eb)
                - HTML attributes appear in light blue (#90e0e8)
                - CSS at-rules appear in pink (#ffc0eb)
                - DOCTYPE declarations appear in grey (#808080)
            - Preprocessor directives appear in grey (#808080)
            - Error text appears in red (#ff0000)

            The syntax highlighting is updated in real-time as text is entered or changed.

            Context: Language detection
                When a code block starts with a language identifier (e.g., ```python), the
                appropriate syntax highlighting rules for that language are applied.
                If no language is specified, the code is treated as plain text with no highlighting.

            Context: Supported languages
                Syntax highlighting is supported for:

                - Python
                - JavaScript/TypeScript
                - HTML
                - CSS
                - C/C++
                - Metaphor

    Context: Menus
        The application will have a series of top-level Menus.

        Where any action cannot be performed at the current time it will be greyed out.

        Context: Humbug
            The "Humbug" menu is the main application menu.  When clicked it contains the following:

            Context: About Humbug
                The "About Humbug" menu item will deliver a modal pop-up dialog box that gives details of the
                application and version information.

            Context: Separator
                There will be a horizontal Separator

            Context: Quit Humbug
                The "Quit Humbug" menu item will allow the user to exit the application.

        Context: File
            The "File" menu handles new files and tabs.  When clicked it contains the following:

            Context: New Conversation
                The "New Conversation" menu item will create a new conversation tab.

                This will be matched with a keyboard shortcut "Ctrl+Shift+N".

            Context: New File
                The "New File" menu item will create a new empty editor tab.

            Context: Separator
                There will be a horizontal Separator

            Context: Open
                The "Open File..." menu item will show a file selection dialog allowing the user to open
                an existing file in a new editor tab.

                This will be matched with a keyboard shortcut (e.g. "Ctrl+O" for Windows).

            Context: Separator
                There will be a horizontal Separator

            Context: Save
                The "Save" menu item will save the current file if it is an editor tab.

                If this is a new untitled file, this will behave like "Save As...".

                This will be matched with a keyboard shortcut (e.g. "Ctrl+S" for Windows).

            Context: Save As
                The "Save As..." menu item will show a file save dialog allowing the user to save the
                current file under a new name.

                This will be matched with a keyboard shortcut (e.g. "Ctrl+Shift+S" for Windows).

            Context: Separator
                There will be a horizontal Separator

            Context: Close Tab
                The "Close Tab" menu item with close the current tab, if a tab is active.

                This will be matched with a keyboard shortcut (e.g. "Ctrl+W" for Windows).

        Context: Edit
            The "Edit" menu handles edit capabilities.  When clicked it contains the following:

            Context: Submit
                The "Submit" menu item will submit the current user input message to the AI, where there is
                an input message to be submitted.

                This will be matched with a keyboard shortcut, "Ctrl+J".

            Context: Separator
                There will be a horizontal Separator

            Context: Undo
                The "Undo" menu item will all the last user input action that has not yet been committed (e.g.
                sent to the AI) to be undone.

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+Z" for Windows).

            Context: Redo
                The "Redo" menu item will restore previos undo operations, where the last user input action has
                not yet been committed (e.g. sent to the AI) to be undone.

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+Shift+Z" for Windows).

            Context: Separator
                There will be a horizontal Separator

            Context: Cut
                The "Cut" menu item will support the cutting of input text from a highlighted area where such
                text can be removed.

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+X" for Windows).

            Context: Copy
                The "Copy" menu item will support the copying of text from a highlighted area.

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+C" for Windows).

            Context: Paste
                The "Paste" menu item will support the pasting of text at the current input cursor, where
                new text can be added.

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+V" for Windows).

            Context: Paste behavior
                When text is pasted into the input area via any method (menu, keyboard shortcuts, or right-click),
                only the plain text content is transferred.  All formatting from the source text (including fonts,
                colours, and text styling) is removed, ensuring the pasted content matches the default input area
                styling.

                After the paste operation completes, the cursor should be at the end of the pasted block.

            Context: Separator
                There will be a horizontal Separator

            Context: Conversation Settings
                The "Conversation Settings" menu item will support setting the conversation settings of
                the currently focused conversation tab (if there is one).

                This will be matched with a standard keyboard shortcut (e.g. "Ctrl+," for Windows).

        Context: View
            The "View" menu handles view settings.  When clicked it contains the following:

            Context: Dark Mode
                The "Dark Mode" menu item will have a checkmark indicating if dark mode is enabled or not.
                By default it will be enabled.

                The application will support a distinct set of light and dark mode colour styling.

            Context: Separator
                There will be a horizontal Separator

            Context: Zoom In
                The "Zoom In" menu item will support zooming in and making the contents of the application
                larger.  All visual elements must increase in size by a factor of 1.189027, up to a maximum
                of 2.0

                This will be matched with a keyboard shortcut (e.g. "Ctrl+=" for Windows).

            Context: Zoom Out
                The "Zoom Out" menu item will support zooming out and making the contents of the application
                smaller.  All visual elements must decrease in size by a factor of 1.189027, down to a minimum
                of 0.5

                This will be matched with a keyboard shortcut (e.g. "Ctrl+-" for Windows).

            Context: Reset Zoom
                The "Reset Zoom" menu item will restore the zoom level of the application to its default 1.0
                of 0.5

                This will be matched with a keyboard shortcut (e.g. "Ctrl+0" for Windows).

        Context: Menu styling
            Menus and menu items must have consistent visual styling:

            - Menu items have 4px border radius for rounded corners
            - Menu items have 8px horizontal padding and 4px vertical padding
            - Menu items highlight with a darker background colour on hover
            - Submenus have a 1px border and 4px border radius

            The specific colours and measurements should scale with the application's zoom level and colour styling.

        Context: Menu state updates
            Menu item states (enabled/disabled) must be updated at least every 50ms to ensure responsive UI
            feedback to user actions.

    Context: File editing
        Editor tabs provide a full-featured text editor with the following capabilities:

        Context: Basic editing
            Standard text editing operations including:

            - Cut/Copy/Paste with standard keyboard shortcuts
            - Undo/Redo functionality
            - Find/Replace functionality
            - Line number display
            - Cursor position display (line:column) in status bar

        Context: Syntax highlighting
            The editor automatically detects and applies syntax highlighting based on file extension
            and content, using the same highlighting rules defined for chat code blocks.

        Context: Save state handling
            The editor tracks changes and maintains a 'dirty' state:

            - Modified files are marked with an asterisk in the tab name
            - Attempting to close a modified file prompts for save
            - Auto-save backups are maintained every 5 minutes if the file has unsaved changes

        Context: Status bar

            The editor status bar shows:

            - Current line and column numbers
            - File encoding (UTF-8, etc.)
            - Line ending style (CRLF, LF)
            - File type based on extension or content

        Context: Editor styling
            The editor uses the same color scheme as the chat interface:

            - Background and text colors match the current theme
            - Selection highlighting matches chat selection behavior
            - Line numbers and gutters use complementary colors

    Context: User/AI interactions
        Each conversation comprises a chat between a user and one or more AI backends.

        If the user starts a message with "/" this indicates a command to the application rather than a message
        for the AI.  The application must process commands as they are presented, stripping the "/" before
        processing..

        Interactions occur in a turn-by-turn fashion, where the user edits a message, until they hit "Ctrl+J".  On
        hitting "Ctrl+J" the application will add the user's message to the conversation transcript and process the
        message.  If the message is for the AI then the application will attempt to send the message to the AI
        and await a response.  If there is an error or exception then the application will report the details to
        the user.

    Context: Conversations
        The bottom line of each conversation window has a status bar.

        The top part of the conversation window will show a history of everything that has happened, including
        messages and commands from the user, responses from the application, and responses from the AI.  Historical
        messages cannot be edited

        Below the conversation history and above the status bar is a user input editor.  This input area will increase
        in size upwards as the user adds more content.  This editable region can be arbitrarily large.

        To the user, the historical details and the editable region must feel like they're one window.  Where they
        are required, there is only one vertical scroll bar to cover both the history and editable area.

        Context: Status bar
            The status bar at the bottom of each conversation window shows:

            - Current AI model name (e.g., "Model: gpt-4o-mini")
            - Temperature setting if applicable (e.g., "Temp: 0.7" or "Temp: N/A" for models without temperature)
            - Input and output token counts since the start of the application

        Context: Highlighting operations
            While the editable and non-editable regions must feel like they're one thing, if the user wants to
            interact with them they will behave differently.  For example, highlighting of text cannot span
            between the editable and non-editable regions.

        Context: Screen colours
            The status line background is light grey with black text.

            Message backgrounds and text colours are:
                - User messages: White text on #3c3c3c background
                - AI responses: White text on #282828 background
                - System messages: White text on #1a3a1a background (dark green)
                - Error messages: White text on #3a1a1a background (dark red)

        Context: Message display
            Messages must automatically adjust their display height based on content.  The height adjustment should
            happen smoothly and in real-time as content is added or removed.

        Context: Conversation Settings
            Each conversation can have its own AI model and temperature settings that affect how the AI responds.

            Context: Settings Dialog
                A "Settings" dialog can be accessed for each conversation via a menu or keyboard shortcut (see
                "Conversation Settings" menu item)

                The dialog shows the current settings for the active conversation tab.

                Context: Model Selection
                    The AI model is selected via a dropdown menu.

                    Available models should be configurable at application startup.

                    The default model is "gpt-4o-mini".

                    Any change to the model selection takes effect on the next message sent to the AI.

                    If a model's provider is not available (no API key), that model should be disabled in the
                    conversation settings.

                Context: Temperature Setting
                    The temperature is set via a numeric input field that:

                    - Accepts values between 0.0 and 1.0
                    - Shows one decimal place
                    - Has spinner arrows for adjustment
                    - Default value is 0.7
                    - Changes take effect on the next message sent to the AI

                Context: Dialog Controls
                    The dialog has:

                    - "OK" button to save changes and close
                    - "Cancel" button to discard changes and close
                    - "Apply" button to save changes without closing

                    The dialog is modal, preventing interaction with the main window while open.

        Context: UI navigation
            Context: Input box navigation
                If the input area has not yet been edited and the cursor is at the top left of the input area, then
                the user can pull up previous historical messages to the AI by using the up and down keys.

        Context: Input formatting
            The input box supports Markdown-style code formatting:

            Context: Code blocks
                Text between matching triple backticks (```) is displayed as a code block.
                Code blocks use a monospace font (set as a family fallback: Menlo, Monaco, Courier New, monospace).
                The background colour for code blocks is dark grey (#2d2d2d) and extends across the full width of the input box.
                The code block formatting applies to both the triple backtick lines and all content between them.

            Context: Inline code
                Text between single backticks (`) is displayed as inline code.
                Inline code uses the same monospace font as code blocks.
                Inline code has no background colour.

            Context: Formatting updates
                The formatting is updated in real-time as the user types.
                When inside a code block, each new line is automatically formatted with the monospace font and background.
                The full width background for code blocks is applied immediately, and not just when a newline is entered.

        Context: History display formatting
            The history display supports the same Markdown-style code formatting as the input box:

            Context: Code blocks
                Text between matching triple backticks (```) is displayed as a code block.
                Code blocks use the same monospace font as the input area (Menlo, Monaco, Courier New, monospace).
                The background colour for code blocks is dark grey (#2d2d2d) and extends across the full width.
                The code block formatting applies to both the triple backtick lines and all content between them.

            Context: Inline code
                Text between single backticks (`) is displayed as inline code.
                Inline code uses the same monospace font as code blocks.
                Inline code has no background colour.

            Context: Formatting interaction
                The Markdown formatting is applied in real-time as messages are added or updated.

    Context: Conversation transcript file
        The application will record a transcript of all conversations between the user and the AI, storing each turn
        in a JSON data structure.  The JSON data structure will be written to a transcript file called
        "transcript-yyyy-mm-dd-hh-mm-ss.json", substituting the application start date and time (in GMT) for yyyy,
        mm, dd, hh, mm, and ss (year, numeric month, day-of-month, hours, minutes, and seconds respectively).

        On exiting the application this file must be fully closed.

        Context: Transcript JSON schema
            Use the following JSON schema:

            ```json
            {
                "$schema": "http://json-schema.org/draft-07/schema#",
                "type": "object",
                "properties": {
                    "metadata": {
                        "type": "object",
                        "properties": {
                            "timestamp": { "type": "string", "format": "date-time" },
                            "version": { "type": "string" },
                            "conversation_number": { "type": "integer" }
                        },
                        "required": ["timestamp", "version", "conversation_number"]
                    },
                    "conversation": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "id": { "type": "string", "pattern": "^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$" },
                                "timestamp": { "type": "string", "format": "date-time" },
                                "type": { "enum": ["user_message", "ai_response", "command", "system_message"] },
                                "content": { "type": "string" },
                                "model": {
                                    "type": "string",
                                    "description": "AI model used (only present for ai_response type)"
                                },
                                "temperature": {
                                    "type": "number",
                                    "minimum": 0,
                                    "maximum": 1,
                                    "description": "Temperature setting used (only present for ai_response type)"
                                },
                                "usage": {
                                    "type": "object",
                                    "properties": {
                                        "prompt_tokens": { "type": "integer" },
                                        "completion_tokens": { "type": "integer" },
                                        "total_tokens": { "type": "integer" }
                                    }
                                },
                                "error": {
                                    "type": "object",
                                    "properties": {
                                        "code": { "type": "string" },
                                        "message": { "type": "string" },
                                        "details": { "type": "object" }
                                    }
                                }
                            },
                            "required": ["id", "timestamp", "type", "content"]
                        }
                    }
                },
                "required": ["metadata", "conversation"]
            }
            ```

    Context: Transcript file management
        Context: Transcript Rotation
            - Max file size: 50MB.
            - On size limit: Create new file with incremented suffix.
            - Keep last 5 transcript files.
            - Delete oldest when limit reached.

        Context: Error recovery
            - Write to temp file first.
            - Atomic rename on successful write.
            - On write failure:
                1. Log error to stderr.
                2. Create backup file.
                3. Continue with new file.

    Context: Commands
        The following are commands the application must support (commands are case sensitive):

        Context: "exit":
            On receiving the "exit" command the application will exit.

        Context: "new":
            Creates a new empty editor tab

        Context: "open":
            Shows the open file dialog

        Context: "save":
            Saves the current file if in an editor tab

        Context: Unknown commands
            If the user types and unknown command then the application will respond that it does not know the
            command.

    Context: State handling
        No state is preserved between different invocations of the application.

    Context: AI interactions
        The AI backend supports streaming responses that arrive incrementally.  These should be displayed
        as they arrive with content continuing to be added as more arrives.

        Context: Streaming responses
            The backend provides chunks containing:

            - Content so far
            - Usage statistics (in final chunk only)

            Streaming requires that the display:

            - Shows content immediately as it arrives
            - Updates transcript periodically during streaming
            - Writes final response when stream completes
            - Updates token count after stream completes

            During streaming, if the user hits "Esc" then this will terminate the current streaming response and cancel
            any ongoing request with the AI.  A message "Request cancelled by user" will be added to the history.

        Context: UI handling of streaming
            The display must handle streaming responses by:

            - Tracking where the streamed response starts in history
            - Updating display incrementally as content arrives
            - Removing previous content before adding updates
            - Maintaining newline format and text wrapping

    Context: Communication with the AI
        Communication with the AI is via a REST API.

        The implementation supports OpenAI and Google Gemini.

        Context: OpenAI REST endpoint
            Messages are sent via a POST message.

            The API to use is the "continuations" API.  The endpoint is "https://api.openai.com/v1/chat/completions".

            This needs two headers to be provided:

            "Content-Type": "application/json"
            "Authorization": {key}"

            {key} must be replaced with the API key found in the environment variable `OPENAI_API_KEY`.

            The data for the POST is of this form:

            ```json
            {
                "model": "selected-model",
                "messages": [{"role": "user", "content": "Say this is a test!"}],
                "temperature": temp-setting,
                "stream": true,
                "stream_options": {"include_usage": true}
            }
            ```

            In this, "selected-model" is name of the selected AI model, and "temp-setting" is the numeric temperature
            setting defined by the user.

            The "content" section of a message should be replaced with the user's message to the AI.
            With streaming enabled, responses will arrive as chunks. Each chunk begins with "data: " followed
            by a JSON object. This repeats until a chunk containing "data: [DONE]" arrives.  Each JSON chunk
            takes this form:

            ```json
            {
                "id": "chatcmpl-abc123",
                "object": "chat.completion.chunk",
                "created": 1677858242,
                "model": "gpt-4o-mini",
                "choices": [
                    {
                        "delta": {
                            "content": "chunk of text"
                        },
                        "finish_reason": null,
                        "index": 0
                    }
                ]
            }
            ```

            The final chunk includes usage information:

            ```json
            {
                "id": "chatcmpl-abc123",
                "object": "chat.completion.chunk",
                "created": 1677858242,
                "model": "gpt-4o-mini",
                "usage": {
                    "prompt_tokens": 13,
                    "completion_tokens": 7,
                    "total_tokens": 20
                },
                "choices": [
                    {
                        "delta": {},
                        "finish_reason": "stop",
                        "index": 0
                    }
                ]
            }
            ```

            In this message, the content is what should be captured as the AI response, but capture the usage information
            in the JSON transcript.

        Context: Google REST endpoint
            Messages are sent via a POST message.

            The API to use is the Gemini streaming API. The endpoint pattern is:

            "https://generativelanguage.googleapis.com/v1beta/models/{model}:streamGenerateContent?alt=sse"

            where {model} is replaced with the selected model name (e.g., "gemini-1.5-flash").

            This needs two headers to be provided:

            "Content-Type": "application/json"
            "x-goog-api-key": {key}

            {key} must be replaced with the API key found in the environment variable `GOOGLE_API_KEY`.

            The data for the POST is of this form:

            ```json
            {
                "contents": [{
                    "parts":[
                        {"text": "User message goes here"}
                    ]
                }],
                "safetySettings": [
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_ONLY_HIGH"
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "topP": 0.8,
                    "topK": 10
                }
            }

            ```

            The temperature value should be omitted for models that don't support it.

            With streaming enabled (alt=sse parameter), responses arrive as Server-Sent Events.

            Each event begins with "data: " followed by a JSON object.

            The stream ends with a "data: [DONE]" message.

            Each JSON chunk takes this form:

            ```json
            {
                "candidates": [
                    {
                        "content": {
                            "parts": [
                                {
                                    "text": "chunk of response text"
                                }
                            ]
                        },
                        "finishReason": null
                    }
                ]
            }
            ```

            The final chunk will have finishReason set to "STOP" and may include usage information.

    Context: Message history
        Maintain conversation context by including all previous messages in the session.

    Context: AI models
        The following AI models are available:

        - "gpt-4o-mini": OpenAI GPT-4 Mini model
        - "gpt-4o": OpenAI GPT-4 model
        - "o1-mini": OpenAI O1 Mini model
        - "o1-preview": OpenAI O1 Preview model
        - "gemini-1.5-flash": Google Gemini 1.5 Flash model
        - "gemini-1.5-pro": Google Gemini 1.5 Pro model
        - "gemini-2.0-flash-exp": Google Gemini 2.0 Flash experimental model

        The AI model is configurable via the settings dialog.  It it set to "gpt-4o-mini" by default.

        Context: Model providers
            Models are provided by different AI services:

            - OpenAI models: "gpt-4o-mini", "gpt-4o", "o1-mini", "o1-preview"
            - Google models: "gemini-1.5-flash", "gemini-1.5-pro"

        Context: Provider configuration
            Each provider requires its own API key:

            - OpenAI models require OPENAI_API_KEY environment variable
            - Google models require GOOGLE_API_KEY environment variable

            At least one provider must be configured for the application to start.

    Context: Temperature settings
        Temperature controls how deterministic or creative the AI's responses are.

        GPT-4o and Gemini models support temperature adjustment:

        - gpt-4o-mini: Supports temperature 0.0-1.0
        - gpt-4o: Supports temperature 0.0-1.0
        - o1-mini: No temperature setting
        - o1-preview: No temperature setting
        - gemini-1.5-flash: Supports temperature 0.0-1.0
        - gemini-1.5-pro: Supports temperature 0.0-1.0
        - gemini-2.0-flash-exp: Supports temperature 0.0-1.1

        Where adjustable, the AI temperature for an AI model will be configurable via the settings dialog.

        The temperature control in the Settings dialog is automatically:

        - Enabled and set to 0.7 by default for GPT-4o models.
        - Disabled for models that do not support a temperature setting.
        - Preserves previous temperature when switching between models that support temperatures.
        - Reverts to default when switching from models that do not support temperatures to a model that does.

    Context: Error handling and recovery
        Context: Handling other network errors
            If there are any API errors, such as invalid API keys then the application should report these to the user
            so they are aware these need to be corrected.

    Context: Error handling and recovery
        Context: Error Categories
            The application handles these error types:

            - Network: Connection, timeout, DNS failures
            - API: Authentication, rate limits, invalid requests
            - Application: Input validation, state corruption
            - System: File IO, memory, permissions

        Context: Network timeouts
            If the AI does not respond within 20 seconds of being sent a request, then the application should treat this as
            a timeout and retry up to 3 times.  Each time it retries, it should report that it is retrying.

        Context: Error response strategy
            For each error:

            - Log full details to transcript
            - Display user-friendly message as an application response.  For example:

                429: "Rate limit exceeded.  Retrying in [X] seconds..."
                500: "OpenAI service error.  Retrying in [X] seconds..."
                timeout: "Request timed out.  Retrying in [X] seconds..."

            - Implement appropriate recovery

            Recovery approach:

            - Network errors: Retry with exponential backoff.  Initial delay 2 seconds, doubling each retry.  Max 3 retries.
            - API errors: Handle rate limits, refresh credentials
            - Application errors: Reset to known good state
            - System errors: Graceful degradation

            During retries, preserve the message in the input box.

        Context: Provider-specific errors
            Each AI provider may return different error formats.  The application must normalize these different error formats
            into a consistent internal format for display and handling.

            Context: OpenAI errors
                OpenAI errors include:

                - Invalid API key
                - Rate limits exceeded
                - Model overloaded

            Context: Gemini errors
                Gemini errors include:

                - Invalid API key
                - Quota exceeded
                - Model not found
                - Invalid request format

        Context: Error display format
            Errors appear in message history with:

            - Severity indicator: [ERROR], [WARNING], [INFO]
            - Clear action message if user intervention needed
            - Technical details in expandable section

        Context: Recovery automation
            Context: Rate Limiting
                Track API calls with sliding 60-second window.

                Pause requests when approaching limits.

            Context: Retry strategy
                Maximum 3 retries for recoverable errors.

                Exponential backoff: 2, 4, 8 seconds.

                Preserve conversation context between retries.

    Context: GUI
        The GUI must be built using the latest version of PySide6, and with qasync to support the integration of this
        and async IO operations.

        Note that PySide6 correctly translates the keyboard shortcuts described into appropriate platform-specific
        shortcuts and no extra logic is required for these.

        Context: Platform support
            The GUI must work on MacOS X (any version since 2020), Linux (any version since 2020), and Microsoft
            Windows 10 or 11.

        Context: Asynchronous design
            The UI must be asynchronous to ensure the application can remain reactive.

        Context: Performance guidelines
            Context: Scrolling performance
                - 60 FPS target for scroll operations

    Context: Security
        Context: Outputs
            Ensure that no sensitive data is either logged or displayed on the screen.

            For example, API keys must never be revealled this way - replace with "[redacted API key]".

        Context: Inputs
            Ensure that all input control characters except for newlines are stripped from any input prior to processing.

    Context: Python implementation and dependencies
        As an engineer working with the application, I want the application to be easy to use and understand,
        so I can maintain and enhance it over time.

        Context: Implement in Python 3
            The application will be written in the latest version of Python 3.

        Context: Indentation of code
            Code must be indented by 4 spaces.

        Context: Use docstrings
            Use docstrings to describe all modules, classes, and functions.  This should follow PEP 257 guidelines.

        Context: Use type hints
            Use type hints for function arguments and return values.

        Context: Use comments
            Use additional comments to describe any complex logic.

        Context: PEP 8 imports
            The import list in any module should follow PEP 8 guidelines, including the ordering of imports.

        Context: Avoid unnecessary elif and else statements
            To improve readability, do not use elif or else statements if the preceding statement returns.

            For example, do this:

            ```
            if condition:
                return

            next_statement()
            ```
            instead of this:
            ```
            if condition:
                return
            else:
                next_statement()
            ```

        Context: Dependencies
            Leverage standard library tools before custom solutions, unless specifically instructed.

            Context: HTTP interations
                Use the aiohttp library for HTTP interactions (e.g. the REST API).

        Context: Exception handling philosophy
            Context: Exception documentation
                Document what exceptions each function may raise in its docstring.

            Context: Handling exceptions
                We should attempt to handle and mitigate exceptions at the level closest to which they are first
                detected.  If we cannot handle or mitigate the exception then it should be wrapped in a domain-appropriate
                exception class and this re-raised to the next level up the call stack.

                Include contextual information when wrapping exceptions.

                Preserve the exception chain using "raise ... from e" syntax.

            Context: Avoid bare "except:" or "except Exception:" clauses.
                We should avoid the use of bare "except:" or "except Exception:" clauses unless a function we are calling
                can only have exceptions handled this way.

                We should always catch specific exception types that could occur from an operation.

            Context: Exception logging
                All exceptions should be logged when they occur, before re-raising or wrapping them.

                Use appropriate log levels:
                - ERROR for exceptions that indicate failure.
                - WARNING for exceptions that can be handled/recovered from.
                - DEBUG for detailed exception information during development.

                We must include sufficient context in log messages to aid debugging.

            Context: Exception wrapping example
                Do this:

                ```python
                try:
                    await self.api_client.fetch_data()
                except ConnectionError as e:
                    logger.error("Failed to retrieve data from API endpoint", exc_info=True)
                    raise DataFetchError(f"Failed to retrieve data from API endpoint: {e}") from e
                except TimeoutError as e:
                    logger.warning("API request timed out, will retry", exc_info=True)
                    # Handle retry logic
                ```

                Not this:

                ```python
                try:
                    await self.api_client.fetch_data()
                except Exception as e:
                    logger.error(f"Error: {e}")  # Insufficient context, no stack trace
                    raise  # No wrapping or additional context
                ```

Action: Build the software
    Please review the requirements provided in the Context section and check if they are met by the software.  Do not
    make modifications to the software at this point, unless asked to do so.
#    Please review the requirements provided in the Context section and build the software described.  Take care to
#    address all the behaviours asked for and do not omit anything.
#
#    Do not produce any other commentary other than the code.
#
#    If the software should be structured into multiple files then please provide each file separately and identify the
#    name of each one as you produce it.

#    An earlier version of the application is provided here.  Please use this as a template.  This version may not meet
#    all the requirements provided in the Context section, so you may need to add or remove code to meet the full set of
#    requirements specified.
#
#    Embed: src/humbug/**/*.py

    An earlier version of most of the application is provided here.  Please use this as a template.  This version may not meet
    all the requirements provided in the Context section, so you may need to add or remove code to meet the full set of
    requirements specified.

    Embed: src/humbug/*.py
    Embed: src/humbug/ai/*.py
    Embed: src/humbug/commands/*.py
    Embed: src/humbug/conversation/*.py
    Embed: src/humbug/gui/*.py
    Embed: src/humbug/transcript/*.py
